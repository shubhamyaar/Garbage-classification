{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5KdkMdRclZ0"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the dataset ZIP file manually\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/archive.zip\"  # Change name if yours is different\n",
        "extract_path = \"/content/garbage_dataset\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "os.listdir(extract_path)  # Check folders\n"
      ],
      "metadata": {
        "id": "2Re-3nnfl4cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "original_data_dir = \"/content/garbage_dataset/TrashType_Image_Dataset\"\n",
        "base_dir = \"/content/garbage_dataset_split\"\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# Create folders again if not exist\n",
        "for folder in [train_dir, val_dir, test_dir]:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "# Split images per class\n",
        "categories = os.listdir(original_data_dir)\n",
        "\n",
        "for category in categories:\n",
        "    category_path = os.path.join(original_data_dir, category)\n",
        "    images = os.listdir(category_path)\n",
        "\n",
        "    train_imgs, temp_imgs = train_test_split(images, test_size=0.3, random_state=42)\n",
        "    val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.5, random_state=42)\n",
        "\n",
        "    for split_type, split_imgs in zip(['train', 'val', 'test'], [train_imgs, val_imgs, test_imgs]):\n",
        "        split_folder = os.path.join(base_dir, split_type, category)\n",
        "        os.makedirs(split_folder, exist_ok=True)\n",
        "\n",
        "        for img in split_imgs:\n",
        "            src = os.path.join(category_path, img)\n",
        "            dst = os.path.join(split_folder, img)\n",
        "            shutil.copy(src, dst)\n",
        "\n",
        "print(\"‚úÖ Dataset re-split into train, val, test.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Pc1AIBzStl-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# =========================\n",
        "# ‚öôÔ∏è Prepare the Data\n",
        "# =========================\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/garbage_dataset_split/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    '/content/garbage_dataset_split/val',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# üß† Load MobileNetV2 Base\n",
        "# =========================\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False  # Freeze base\n",
        "\n",
        "# =========================\n",
        "# üß± Build the Model Head\n",
        "# =========================\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# =========================\n",
        "# ‚öôÔ∏è Compile the Model\n",
        "# =========================\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# =========================\n",
        "# ‚è±Ô∏è Setup Callbacks\n",
        "# =========================\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.5)\n",
        "\n",
        "# =========================\n",
        "# üöÄ Train the Model\n",
        "# =========================\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stop, lr_reduce]\n",
        ")\n"
      ],
      "metadata": {
        "id": "QAEGXeXiUxRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=25,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "predictions = Dense(train_gen.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen\n",
        ")\n"
      ],
      "metadata": {
        "id": "FwztQ1_vuCe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KbtMinXA8etU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/garbage_classifier_mobilenetv2.h5\")\n",
        "print(\"‚úÖ Model saved.\")\n"
      ],
      "metadata": {
        "id": "MAESod1eFw1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model you saved earlier\n",
        "model = load_model(\"/content/garbage_classifier_mobilenetv2.h5\")\n",
        "print(\"‚úÖ Model loaded.\")\n"
      ],
      "metadata": {
        "id": "p-LdYYbsHTsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from IPython.display import display\n",
        "import PIL.Image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    print(f\"üì∏ Uploaded file: {fn}\")\n",
        "    img = PIL.Image.open(fn)\n",
        "    display(img)\n",
        "\n",
        "    # Predict\n",
        "    preprocess_and_predict(fn, model, class_indices)\n"
      ],
      "metadata": {
        "id": "0xBqqlSQJe-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator.class_indices\n"
      ],
      "metadata": {
        "id": "gjrLFZfbT3zG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model.evaluate(val_generator)\n",
        "print(f\"üìä Final Val Accuracy: {val_acc:.2f}\")\n"
      ],
      "metadata": {
        "id": "gLtVlMuggPZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"garbage_classifier_mobilenetv2.h5\")\n"
      ],
      "metadata": {
        "id": "zy8KvE-bgju-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load your trained model\n",
        "model = load_model(\"garbage_classifier_mobilenetv2.h5\")\n",
        "print(\"‚úÖ Model loaded.\")\n"
      ],
      "metadata": {
        "id": "9D0eo2jYg52X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Upload an image\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 2: Get the uploaded filename\n",
        "filename = list(uploaded.keys())[0]\n",
        "print(f\"‚úÖ Uploaded: {filename}\")\n",
        "\n",
        "# Step 3: Preprocess the image\n",
        "def preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))  # resize to model's input\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # add batch dimension\n",
        "    img_array = img_array / 255.0  # normalize\n",
        "    return img_array\n",
        "\n",
        "# Step 4: Predict and Show\n",
        "def predict_image(img_path, model):\n",
        "    img_array = preprocess_image(img_path)\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "    # Get class labels\n",
        "    class_labels = list(train_generator.class_indices.keys())  # assumes train_generator was used earlier\n",
        "    predicted_label = class_labels[predicted_class_index]\n",
        "\n",
        "    # Show image and prediction\n",
        "    img = PIL.Image.open(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Prediction: {predicted_label}\")\n",
        "    plt.show()\n",
        "\n",
        "# Step 5: Call prediction\n",
        "predict_image(filename, model)\n"
      ],
      "metadata": {
        "id": "m6r1PiZth-Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('garbage_classifier_mobilenetv2.h5')  # e.g. model.h5\n"
      ],
      "metadata": {
        "id": "hJZatkgcjnuQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}